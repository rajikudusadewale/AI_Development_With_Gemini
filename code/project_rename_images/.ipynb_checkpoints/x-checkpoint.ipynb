{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3602543e-1044-43d5-8240-d2ac578a46f0",
   "metadata": {},
   "source": [
    "# Project: Renaming Images using AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7fa048-121f-4306-ae98-7028b815cdb3",
   "metadata": {},
   "source": [
    "## 01 - Project Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c5e40-1e9b-41c0-ad88-6a29965948ea",
   "metadata": {},
   "source": [
    "This project started as something small I needed for myself. See, I take and receive a ton of photos, and they end up in these folders of files with meaningless names. Searching for one specific picture? It's a nightmare.\n",
    "\n",
    "What I really needed was an app that uses fancy AI to take a peek at each image, come up with a good name based on what's *in* the picture, and then rename the file. Finally, images with names that actually make sense!\n",
    "\n",
    "Okay, in this section, I'll walk you through how to build this project step by step. We'll use the Gemini AI model, and I'll even throw in some cool Python tips that are useful for all sorts of stuff, like generators and working with file paths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da415e9-e435-4d9c-a5c5-d03e5adf7eb0",
   "metadata": {},
   "source": [
    "## 02 - Getting Images Using a Generator\n",
    "\n",
    "In this video, I'll show you an efficient way to find all images within a directory and its subdirectories. This isn't just about images – this Python code you can use in tons of applications.\n",
    "\n",
    "We'll also explore some cool advanced Python concepts like working with paths, files and generators. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0def0c13-a625-462d-830b-e40a33d740ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2c4b5cd6-9705-4df6-90cc-deb517026f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm importing the 'os' module for working with files and directories\n",
    "import os \n",
    "\n",
    "# I'm importing the 'Path' class for easier file path handling\n",
    "from pathlib import Path \n",
    "\n",
    "# I'm also importing the 'Image' class from PIL because Gemini Pro Vision works with PIL images\n",
    "from PIL import Image  \n",
    "\n",
    "# You are probably thinking that a function that returns all images from a directory is appropriate.\n",
    "# However this is not efficient.\n",
    "\n",
    "# Imagine you have a huge folder filled with thousands of images. \n",
    "# Using a regular function, you'd first need to find all the images, load them into memory, and then start processing them.\n",
    "# That'd use a ton of space!\n",
    "\n",
    "# Generators are way smarter. They find one image, hand it to you, then go find the next.\n",
    "# It's like streaming – you only deal with one image at a time, which saves a bunch of memory.\n",
    "\n",
    "\n",
    "# As a quick refresher on functions vs. generators, functions run to completion, returning all the results at once.\n",
    "# Generators, on the other hand, are like a \"lazy worker.\". They find one result, pause, then give it to you when asked. \n",
    "# Perfect for handling big datasets or when you don't need everything right away.\n",
    "\n",
    "def get_images(directory):\n",
    "\n",
    "    # This will be a generator, not a function.\n",
    "\n",
    "      # I'm defining a tuple of supported image file extensions \n",
    "      supported_extensions = ('.png', '.jpg', '.jpeg', '.gif')\n",
    "    \n",
    "      # Let's loop through the directory structure using os.walk().\n",
    "      # os.walk() is a generator that goes through each directory and gives us \n",
    "      # the current directory (root), any unused subdirectories (which I'll call _), \n",
    "      # and a list of files in the current directory (filenames).\n",
    "      for root, _, filenames in os.walk(directory): \n",
    "    \n",
    "        # Let's loop over the filenames\n",
    "        for filename in filenames: \n",
    "          # I'll check if the filename ends with a supported extension, \n",
    "          # and I'll make the check case-insensitive.\n",
    "          if filename.lower().endswith(supported_extensions):  \n",
    "    \n",
    "            # Let's build the full absolute path to the image file. \n",
    "            absolute_path = os.path.join(root, filename)  \n",
    "    \n",
    "            # I'm opening the image as a PIL image object, ready for Gemini.\n",
    "            img = Image.open(absolute_path)  \n",
    "    \n",
    "            # Since this is a generator, I'm using 'yield' to return the image \n",
    "            # object and the full image path. \n",
    "            yield img, absolute_path  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8f42f766-0529-41ba-a7fd-9fa0193cf0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=370x582 at 0x73E27614DBB0> ./images/open_fridge_full_of_food.png\n",
      "\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=695x760 at 0x73E27614C890> ./images/shakshuka_eggs_tomatoes_peppers_cilantro.jpg\n",
      "\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=793x412 at 0x73E27614F4D0> ./images/toy_poodle_puppy_eating_cucumber.jpg\n",
      "\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x866 at 0x73E27614FC50> ./images/salad_bowl_with_greens_and_fruits.jpg\n",
      "\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=418x927 at 0x73E27614FCE0> ./images/sagrada_familia_barcelona_gaudi_architecture_cathedral_facade.jpg\n",
      "\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=793x412 at 0x73E27614F7D0> ./images/cal/puppy_eating_cucumber.jpg\n",
      "\n",
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=695x760 at 0x73E27614FEF0> ./images/cal/shakshuka_in_a_pan.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's check the generator\n",
    "# I will iterate over the value it yields\n",
    "for img, absolute_path in get_images('./images'):\n",
    "    print(img, absolute_path)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc087982-5e3d-42f7-9e80-70ff6196242a",
   "metadata": {},
   "source": [
    "## 03 - Renaming Images Using Gemini Pro Vision Suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b58e40-27ae-4a65-a7db-2e9a8b363bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm importing the necessary libraries and performing the authetication to Gemini.\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True) \n",
    "genai.configure(api_key=os.environ.get('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "273d7739-516c-4f05-b8b8-73a168880df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/sagrada_familia_barcelona_gaudi.jpg was renamed to ./images/vacation_paris_2024_sagrada_familia_barcelona_gaudi.jpg\n",
      "--------------------------------------------------\n",
      "./images/salad_bowl_with_greens_and_fruit.jpg was renamed to ./images/vacation_paris_2024_colorful_salad_bowl.jpg\n",
      "--------------------------------------------------\n",
      "./images/open_fridge_full_of_food.png was renamed to ./images/vacation_paris_2024_open_fridge_full_of_food.png\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "InternalServerError",
     "evalue": "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Now, let's process each image in the directory using an iteration\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, absolute_path \u001b[38;5;129;01min\u001b[39;00m get_images(my_directory):\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# I'm making the API call sending the image and the prompt to Gemini for analysis:\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Gemini's answer will not preserve the image extension. It will respond only with a description of the image that will be the new name.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# I will need the original file extension and I'm getting it by calling os.path.splitext()\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     root, ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(absolute_path) \u001b[38;5;66;03m# this method takes an absolute path as an argument and split it into two components:\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/python/AI_Notebooks_OpenAI_LangChain_Copilot_Gemini/venv312/lib/python3.12/site-packages/google/generativeai/generative_models.py:232\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, request_options)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n",
      "File \u001b[0;32m~/projects/python/AI_Notebooks_OpenAI_LangChain_Copilot_Gemini/venv312/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:566\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    561\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m    562\u001b[0m     gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata(((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmodel),)),\n\u001b[1;32m    563\u001b[0m )\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 566\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/projects/python/AI_Notebooks_OpenAI_LangChain_Copilot_Gemini/venv312/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/python/AI_Notebooks_OpenAI_LangChain_Copilot_Gemini/venv312/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/python/AI_Notebooks_OpenAI_LangChain_Copilot_Gemini/venv312/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m~/projects/python/AI_Notebooks_OpenAI_LangChain_Copilot_Gemini/venv312/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/projects/python/AI_Notebooks_OpenAI_LangChain_Copilot_Gemini/venv312/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/projects/python/AI_Notebooks_OpenAI_LangChain_Copilot_Gemini/venv312/lib/python3.12/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/python/AI_Notebooks_OpenAI_LangChain_Copilot_Gemini/venv312/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mInternalServerError\u001b[0m: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting"
     ]
    }
   ],
   "source": [
    "# I'm creating the model object. The LLM will use both text and an image as inputs so gemini pro vision is the good model for this.\n",
    "model = genai.GenerativeModel('gemini-pro-vision')\n",
    "\n",
    "# I'm creating the prompt for the image analysis and renaming task\n",
    "prompt = '''Analyze this image in detail. \n",
    "Generate a descriptive image filename using only these rules:\n",
    "* Relevant keywords describing the image, separated by underscores.\n",
    "* Lowercase letters only.\n",
    "* No special characters.\n",
    "* Keep it short and accurate.\n",
    "Respond ONLY with the image filename (no extension).\n",
    "\n",
    "Example: child_running_in_the_rain\n",
    "''' \n",
    "\n",
    "# I used prompt engineering to get the best results. This prompt is effective because:\n",
    "# * I give clear instructions, one per line.\n",
    "# * I specify the exact output format I want. \n",
    "# * I avoid spaces in filenames, as they can cause issues on some systems.\n",
    "# * I include a helpful example.\n",
    "\n",
    "# I'm setting the directory containing the images\n",
    "my_directory = \"./images\"  \n",
    "\n",
    "# Now, let's process each image in the directory using an iteration\n",
    "for img, absolute_path in get_images(my_directory):\n",
    "\n",
    "    # I'm making the API call sending the image and the prompt to Gemini for analysis:\n",
    "    response = model.generate_content([prompt, img ])\n",
    "    \n",
    "    # Gemini's answer will not preserve the image extension. It will respond only with a description of the image that will be the new name.\n",
    "    # I will need the original file extension and I'm getting it by calling os.path.splitext()\n",
    "    root, ext = os.path.splitext(absolute_path) # this method takes an absolute path as an argument and split it into two components:\n",
    "    # root and extension\n",
    "\n",
    "    # I will show you an example in another cell to see how it works.\n",
    "    # I'm using Linux or Mac paths but it works the same with Windows paths.\n",
    "\n",
    "\n",
    "    # Root is the part of the path before the last period which is the extension. It  includes the directories leading up to the filename.\n",
    "    \n",
    "    # Next I will build the new filename, keeping the original extension.\n",
    "    new_filename =  response.text.strip() + ext # I'm calling strip() to remove any whitespaces before or after the response. \n",
    "    # In practice I noticed that sometimes Gemini is adding a trailing whitespace.\n",
    "\n",
    "    # I'll need the full path for the new image which is composed of a base dir and the new filename\n",
    "    base_dir = os.path.dirname(absolute_path)\n",
    "    new_filepath = base_dir + '/' + new_filename\n",
    "\n",
    "\n",
    "    # I will call os.rename() to rename the file, but first I want to check that everyhing works as it is expected. \n",
    "    # All images are processed correctly by gemini, the absolute path and the extension are preservered and so on\n",
    "    os.rename(absolute_path, new_filepath) # //** add at the end\n",
    "\n",
    "    # I'm displaying a message for the user\n",
    "    print(f'{absolute_path} was renamed to {new_filepath}')\n",
    "\n",
    "    print('-' * 50)\n",
    "\n",
    "\n",
    "# Okay, let's run the code! You'll see Gemini analyze each image and come up with a descriptive new filename \n",
    "# – just like we asked in the prompt.\n",
    "\n",
    "# I'm adding the renaming part now!\n",
    "\n",
    "# I'm running the code again,  noticing how the application is renaming all the file in this directory and its subdirectories.\n",
    "\n",
    "# In this example, I renamed the files according to Gemini's response. However, you can add a prefix or a suffix to your images if you wish.\n",
    "# For example, I'm adding 'vacation_paris_2024_' at the beginning.\n",
    "\n",
    "# That's it! You learned how to rename your meaningless image names in a smart way using AI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2db300-07ab-440b-80a9-5724e3be6b7a",
   "metadata": {},
   "source": [
    "### -----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dcabbddd-e963-4438-bab4-95d42a89bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/documents/project/image .jpg\n"
     ]
    }
   ],
   "source": [
    "root, ext = os.path.splitext('/home/user/documents/project/image.jpg')\n",
    "print(root, ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "57e3f38d-c62e-41c4-8b4c-a3f8543ea9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/user/documents/project'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absolute_path = '/home/user/documents/project/image.jpg'\n",
    "base_dir = os.path.dirname(full_path)\n",
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "49b829bc-6326-4044-9de1-22fcf718d52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/user/documents/project/image'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base, ext = os.path.splitext(absolute_path)\n",
    "base"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
